# Base configuration
seed: 42
device: "mps"

# Model configuration
model:
  type: ["GATv2", "GINE"] # Model architectures to test
  activation: 'relu' # Default activation
  hidden_channels: 32 # Default hidden dimension
  num_layers: 1 # Default number of layers
  dropout: 0.3 # Default dropout rate
  residual: True
  heads: 1
  use_edge_encoders: False
  use_classifier_mlp: False
  classifier_mlp_dims: []

# Training configuration
training:
  learning_rate: 1e-3
  batch_size: 128
  max_epochs: 32
  patience: 8
  lr_patience: 4
  lr_factor: 0.5
  weight_decay: 1e-5
  cv_folds: 3
  mixed_precision: True
  log_interval: 20

# Hyperparameter search space
hparams:
  activation:
    options: ["relu", "tanh", "leaky_relu"]
  hidden_channels:
    min: 4
    max: 512
  num_layers:
    min: 1
    max: 4
  dropout:
    min: 0.01
    max: 0.5
  heads:
    min: 1
    max: 5
  learning_rate:
    min: 1e-5
    max: 1e-2
  classifier_mlp_dims:
    options: [[32], [64], [32, 16], [64, 32]]

# Optuna configuration
optuna:
  n_trials: 16
  n_startup_trials: 2
  n_warmup_steps: 5
  timeout: 86400 # 24 hours in seconds

data:
  dataset_path: "data/tabular/processed_graphs.pkl"
  datasets: ["plrx", 'spectf', 'liver', 'blood', 'diabetic', 'Immunotherapy', 'spect']
